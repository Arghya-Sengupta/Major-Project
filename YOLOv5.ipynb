{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arghya-Sengupta/Major-Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this code to clone the yolov5 repository from github\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "from yolov5 import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "id": "lJSuTAFu0SEM",
        "outputId": "53bbc3d0-211a-4508-e0e9-4f9e4f9f5613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.1-135-g7926afc torch 1.10.0+cu111 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.6/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !unzip -q /content/drive/MyDrive/Data/sample_data.zip -d /content/\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/custom_coco.yaml\" \"/content/yolov5/data/\"\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/custom_detect.py\" \"/content/yolov5/\"\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/result.txt\" \"/content/\"\n",
        "print(\"All 3 files copied.\")"
      ],
      "metadata": {
        "id": "BkgJ2Kn2tOrZ",
        "outputId": "9cdd207d-06c6-4c53-d7ce-26346fd1a1ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "All 3 files copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # code for resizing the images\n",
        "# # changing pixels to res x res\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "# from os import listdir\n",
        "# from PIL import Image\n",
        "\n",
        "# directory = '/content/drive/MyDrive/Data/Original_Images_Large/'\n",
        "# nc = 5\n",
        "# res = 800\n",
        "\n",
        "# os.makedirs('/content/drive/MyDrive/Data/Original_Images')\n",
        "# for i in range(1,nc+1):\n",
        "#     os.mkdir('/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/')\n",
        "\n",
        "# for i in range(1,nc+1):\n",
        "#     shutil.copy2(directory + str(i) + '/bb_info.txt', '/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/')\n",
        "\n",
        "# for i in range(1,nc+1):\n",
        "#     print(\"Working on \"+str(i))\n",
        "#     new_dir = directory + str(i) + '/'\n",
        "#     for f in listdir(new_dir):\n",
        "#         if f.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "#             image = Image.open(new_dir + f)\n",
        "#             # image = image.resize((res,res),Image.ANTIALIAS)\n",
        "#             image.save('/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/' + f)\n",
        "# print(\"Completed\")"
      ],
      "metadata": {
        "id": "rZJXoxwBsPCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for modifying the bounding boxes in yolo format\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# modify the directories accordingly\n",
        "datapath = '/content/drive/MyDrive/Data/Original_Images'\n",
        "labelpath = '/content/drive/MyDrive/Data/Original_Images/labels'\n",
        "classfilename = '/content/drive/MyDrive/Data/For_Colab/foods.names'\n",
        "\n",
        "def convert_yolo_bbox(img_size, box):\n",
        "    # img_bbox file format is [0:img] [1:left X] [2:bottom Y] [3:right X] [4:top Y]\n",
        "    dw = 1./img_size[0]\n",
        "    dh = 1./img_size[1]\n",
        "    x = (int(box[1]) + int(box[3]))/2.0\n",
        "    y = (int(box[2]) + int(box[4]))/2.0\n",
        "    w = abs(int(box[3]) - int(box[1]))\n",
        "    h = abs(int(box[4]) - int(box[2]))\n",
        "    x *= dw\n",
        "    w *= dw\n",
        "    y *= dh\n",
        "    h *= dh\n",
        "    # yolo_bbox file format is center x, y and width, height\n",
        "    return (x,y,w,h)\n",
        "\n",
        "def generate_bbox_file(classid):\n",
        "    dataDir = os.path.join(datapath, str(classid))\n",
        "    labelDir = os.path.join(labelpath, str(classid))\n",
        "    bb_filename = os.path.join(dataDir, 'bb_info.txt')\n",
        "    if not os.path.exists(labelDir):\n",
        "        os.makedirs(labelDir)\n",
        "    with open(bb_filename) as fp:\n",
        "        for line in fp.readlines():\n",
        "            # img_bbox file is [0:img] [1:left X] [2:bottom Y] [3:right X] [4:top Y]\n",
        "            img_bbox = line.strip('\\n').split(' ')\n",
        "            if img_bbox[0] != 'img':\n",
        "                image_filename = os.path.join(dataDir, img_bbox[0]+'.jpg')\n",
        "                yolo_label_filename = os.path.join(labelDir, img_bbox[0]+'.txt')\n",
        "                with open(yolo_label_filename, 'w') as f:\n",
        "                    img = Image.open(image_filename)\n",
        "                    yolo_bbox = convert_yolo_bbox(img.size, img_bbox)\n",
        "                    # if (yolo_bbox[2] > 1) or (yolo_bbox[3] > 1):\n",
        "                    #     print(\"image %s bbox is \" %(image_filename) + ' '.join(map(str, yolo_bbox)))\n",
        "                    f.write(str(classid-1) + ' ' + ' '.join(map(str, yolo_bbox)) + '\\n')\n",
        "                    img.close()\n",
        "                    f.close()\n",
        "        fp.close()\n",
        "\n",
        "classid = 0\n",
        "classid2name = {}\n",
        "if os.path.exists(classfilename):\n",
        "    with open(classfilename) as cf:\n",
        "        for line in cf.readlines():\n",
        "            classname = line.strip('\\n')\n",
        "            classid = classid + 1\n",
        "            classid2name[classid] = classname\n",
        "\n",
        "for id in classid2name.keys():\n",
        "    print(\"Generating %d %s\" %(id, classid2name[id]))\n",
        "    generate_bbox_file(id)\n",
        "print('Completed')"
      ],
      "metadata": {
        "id": "I6AhF2sshOQv",
        "outputId": "e12a6758-1ddc-494d-a9b3-a340a57f5fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 1 rice\n",
            "Generating 2 toast\n",
            "Generating 3 omelet\n",
            "Generating 4 fish\n",
            "Generating 5 salad\n",
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the \"Training_Images\" folder first (if present)\n",
        "# %rm -rf /content/UECFOOD100\n",
        "# code for spliting both images and labels for training and validation\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from os.path import isfile, join\n",
        "from random import randint\n",
        "from os import listdir\n",
        "\n",
        "directory = '/content/drive/MyDrive/Data/Original_Images/'\n",
        "nc = 5\t# number of catagories\n",
        "\n",
        "def make_directories():\n",
        "\tos.makedirs('/content/drive/MyDrive/Data/Training_Images/images/train')\n",
        "\tos.mkdir('/content/drive/MyDrive/Data/Training_Images/images/val/')\n",
        "\tos.makedirs('/content/drive/MyDrive/Data/Training_Images/labels/train')\n",
        "\tos.mkdir('/content/drive/MyDrive/Data/Training_Images/labels/val/')\n",
        "\n",
        "def split_files(probability):\n",
        "\tt=0\n",
        "\tv=0\n",
        "\tfor i in range(1,nc+1):\n",
        "\t\tprint(\"Working on \"+str(i))\n",
        "\t\tnew_dir = directory + str(i) + '/'\n",
        "\t\tfor f in listdir(new_dir):\n",
        "\t\t\tif isfile(join(new_dir, f)) and f.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "\t\t\t\tfile_name = os.path.splitext(f)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tif(randint(1, 100) <= probability):\t\n",
        "\t\t\t\t\tsplit = 'train/'\n",
        "\t\t\t\t\tt +=1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsplit = 'val/'\n",
        "\t\t\t\t\tv += 1\n",
        "\n",
        "\t\t\t\timgage_src = new_dir + f\n",
        "\t\t\t\timgage_dst = \"/content/drive/MyDrive/Data/Training_Images/images/\" + split\n",
        "\n",
        "\t\t\t\tlabel_src = directory + \"labels/\" + str(i) + \"/\" + file_name + \".txt\"\n",
        "\t\t\t\tlabel_dst = \"/content/drive/MyDrive/Data/Training_Images/labels/\" + split\n",
        "\n",
        "\t\t\t\tshutil.copy2(imgage_src, imgage_dst)\n",
        "\t\t\t\tshutil.copy2(label_src, label_dst)\n",
        "\tprint(\"\\n\" + str(t) + \" (\" + str(100.0*t/(t+v)) + \" %) Images for training\")\n",
        "\tprint(str(v) + \" (\" + str(100.0*v/(t+v)) + \" %) Images for validation\")\n",
        "\n",
        "make_directories()\n",
        "split_files(70)\t# 70% for training and 30% for validation\n",
        "print(\"\\nTraining images stored in Google Drive under /Data/Training_Images/\")"
      ],
      "metadata": {
        "id": "8Boiut0khZuV",
        "outputId": "81dd2f0c-d446-46ee-d021-df9c6fa69c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on 1\n",
            "Working on 2\n",
            "Working on 3\n",
            "Working on 4\n",
            "Working on 5\n",
            "\n",
            "358 (71.6 %) Images for training\n",
            "142 (28.4 %) Images for validation\n",
            "\n",
            "Training images stored in Google Drive under /Data/Training_Images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do with 60 epochs for best results\n",
        "\n",
        "# !python train.py --img 800 --batch 4 --epochs 3 --data /content/yolov5/data/custom_coco.yaml --weights yolov5s.pt --cache\n",
        "!python train.py --batch 2 --epochs 15 --data /content/yolov5/data/custom_coco.yaml --weights /content/yolov5/65_epochs_with_new_data.pt --cache\n",
        "# From 66 epochs\n",
        "\n",
        "# runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "id": "yAJDyLpD0yYN",
        "outputId": "dcfcad45-45c7-4ac0-af97-84d7eb3d0fae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/65_epochs_with_new_data.pt, cfg=, data=/content/yolov5/data/custom_coco.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.1-135-g7926afc torch 1.10.0+cu111 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7033114 parameters, 7033114 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /content/yolov5/65_epochs_with_new_data.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/Data/Training_Images/labels/train.cache' images and labels... 350 found, 0 missing, 0 empty, 0 corrupt: 100% 350/350 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/5854.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/81.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/83.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/85.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/87.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/98.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 350/350 [00:05<00:00, 63.13it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Data/Training_Images/labels/train.cache' images and labels... 350 found, 0 missing, 0 empty, 0 corrupt: 100% 350/350 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/5854.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/81.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/83.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/85.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/87.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/drive/MyDrive/Data/Training_Images/images/train/98.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 350/350 [00:03<00:00, 112.41it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.41 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/14        0G   0.01549   0.01241  0.004959         6       640: 100% 175/175 [06:56<00:00,  2.38s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.947      0.977      0.986      0.766\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/14        0G   0.01414   0.01002  0.002834         6       640: 100% 175/175 [06:49<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.925      0.978      0.976      0.644\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/14        0G   0.01949    0.0105  0.003067         5       640: 100% 175/175 [06:48<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.821      0.954      0.879      0.568\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/14        0G   0.02218   0.01035  0.002972         4       640: 100% 175/175 [06:48<00:00,  2.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.953      0.944      0.978      0.653\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/14        0G   0.02128   0.01128   0.00384         5       640: 100% 175/175 [06:49<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.938      0.979      0.979      0.679\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/14        0G   0.01994   0.01114  0.004516         9       640: 100% 175/175 [06:49<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.957      0.955      0.979      0.628\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/14        0G    0.0203    0.0106  0.004043         4       640: 100% 175/175 [06:49<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357       0.94      0.968       0.98       0.69\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/14        0G   0.01749   0.01094  0.003502         8       640: 100% 175/175 [06:48<00:00,  2.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.966       0.95      0.984      0.718\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/14        0G   0.01679   0.01037  0.003491         3       640: 100% 175/175 [06:48<00:00,  2.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.946      0.952      0.982      0.652\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/14        0G   0.01619   0.01145  0.003853         8       640: 100% 175/175 [06:48<00:00,  2.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.939      0.992      0.986      0.731\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/14        0G   0.01556   0.01156  0.003703         7       640: 100% 175/175 [06:48<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.954      0.992       0.99      0.725\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/14        0G   0.01712   0.01204   0.00477         4       640: 100% 175/175 [06:49<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.963       0.97      0.989      0.756\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/14        0G    0.0148   0.01208  0.004074         6       640: 100% 175/175 [06:48<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.949      0.984      0.986      0.752\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/14        0G   0.01553   0.01205  0.004912         3       640: 100% 175/175 [06:48<00:00,  2.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.962      0.981      0.988      0.763\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/14        0G   0.01492   0.01206  0.004865         5       640: 100% 175/175 [06:48<00:00,  2.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:38<00:00,  1.12s/it]\n",
            "                 all        350        357      0.955      0.984      0.986      0.768\n",
            "\n",
            "15 epochs completed in 2.118 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 88/88 [01:34<00:00,  1.07s/it]\n",
            "                 all        350        357      0.955      0.984      0.986      0.768\n",
            "                rice        350         65       0.89          1       0.98      0.784\n",
            "               toast        350         76      0.996      0.987      0.995      0.802\n",
            "              omelet        350         65      0.968          1      0.987      0.733\n",
            "                fish        350         75      0.973      0.948      0.975      0.723\n",
            "               salad        350         76      0.949      0.987      0.992      0.798\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy best.pt in Google Drive\n",
        "import shutil\n",
        "\n",
        "shutil.copy2(\"/content/yolov5/runs/train/exp/weights/best.pt\" , \"/content/drive/MyDrive/Data/Weights_Files\")\n",
        "print(\"Weight file Copied.\")"
      ],
      "metadata": {
        "id": "E0w9VRv6rZUs",
        "outputId": "3fafa996-2acc-462d-8d2f-9dde49ed0964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight file Copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from calculate_calories import *\n",
        "\n",
        "# total_calorie = get_foods()\n",
        "# print(\"Total Calories = \",total_calorie)\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "path = \"/content/drive/MyDrive/Data/\"\n",
        "detection_path = path +  \"Detection_Images/\"\n",
        "results_path = path + \"Results/\"\n",
        "N = len(os.listdir(detection_path))\n",
        "if not os.path.exists(results_path):\n",
        "\tos.mkdir(results_path)\n",
        "start = time.time()\n",
        "\n",
        "for test_file in os.listdir(detection_path):\n",
        "\tcommand = \"python /content/yolov5/custom_detect.py --weights /content/yolov5/65_epochs_with_new_data.pt --conf 0.5 --source \" + detection_path + test_file\n",
        "\tprint(\"Detecting\",test_file)\n",
        "\tstatus = os.system(command)\n",
        "\tif(status != 0):\n",
        "\t\tprint(test_file,\"not found\")\n",
        "print(f\"Detection Completed in {round(time.time()-start, 2)}s\")"
      ],
      "metadata": {
        "id": "HqHDViXe4u6s",
        "outputId": "ad73e75c-992b-46cd-b4e7-dafe49004be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection Completed in 0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write calorie on the result images\n",
        "\n",
        "# Importing the PIL library\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "# Open an Image\n",
        "img = Image.open(\"/content/test.jpg\")\n",
        "\n",
        "# Call draw Method to add 2D graphics in an image\n",
        "I1 = ImageDraw.Draw(img)\n",
        "\n",
        "# Custom font style and font size\n",
        "myFont = ImageFont.truetype(r'/content/arial.ttf',40)\n",
        "\n",
        "# Add Text to an image\n",
        "I1.text((0, 0), \"Noice\", font=myFont, fill =(255, 0, 0))\n",
        "\n",
        "# Display edited image\n",
        "img.show()\n",
        "\n",
        "# Save the edited image\n",
        "img.save(\"/content/result2.jpg\")\n"
      ],
      "metadata": {
        "id": "o2SEq3mmYKYy",
        "outputId": "066ef2a4-010f-46b1-ae55-c39543ab4895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2e3edae0d445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Open an Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/test.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Call draw Method to add 2D graphics in an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# calorie_file = pd.read_csv('/content/Calorie_Data.csv')\n",
        "# result_file = '/content/result.txt'\n",
        "\n",
        "# def search(food):\n",
        "# \ti = 0\n",
        "# \tfor food_name in calorie_file.Food_Name:\n",
        "# \t\tif(food.lower() == food_name.lower()):\n",
        "# \t\t\treturn i\n",
        "# \t\ti += 1\n",
        "# \treturn 0\n",
        "\n",
        "# def get_foods():\n",
        "# \ttotal = 0\n",
        "# \twith open(result_file) as result:\n",
        "# \t\tfor food in result:\n",
        "# \t\t\tfood = food.strip()\n",
        "# \t\t\tif(food is ''):\n",
        "# \t\t\t\tcontinue\n",
        "# \t\t\tcalorie = calorie_file.Calories[search(food)]\n",
        "# \t\t\ttotal += calorie\n",
        "# \treturn total\n",
        "\n",
        "# total_calorie = 0\n",
        "# total_calorie = get_foods()\n",
        "# print(\"Total Calories = \",total_calorie)"
      ],
      "metadata": {
        "id": "jHV_58npkM2n",
        "outputId": "38b08c5d-7eae-4291-9d05-5f2bc9f12cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Calories =  15\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "YOLOv5",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}