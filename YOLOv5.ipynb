{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arghya-Sengupta/Major-Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this code to clone the yolov5 repository from github\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "from yolov5 import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "id": "lJSuTAFu0SEM",
        "outputId": "63cabb74-32a2-4861-ec8a-c8a01377da59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.1-110-g0ca85ed torch 1.10.0+cu111 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.6/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you are using google colab\n",
        "# run this code to fetch data from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !unzip -q /content/drive/MyDrive/Data/sample_data.zip -d /content/\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/custom_coco.yaml\" \"/content/yolov5/data/\"\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/custom_detect.py\" \"/content/yolov5/\"\n",
        "!cp \"/content/drive/MyDrive/Data/For_Colab/result.txt\" \"/content/\"\n",
        "print(\"All 3 files copied.\")"
      ],
      "metadata": {
        "id": "BkgJ2Kn2tOrZ",
        "outputId": "1f0b9636-2b2f-4f61-ca87-6f25bf5b2fc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "All 3 files copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # code for resizing the images\n",
        "# # changing pixels to res x res\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "# from os import listdir\n",
        "# from PIL import Image\n",
        "\n",
        "# directory = '/content/drive/MyDrive/Data/Original_Images_Large/'\n",
        "# nc = 5\n",
        "# res = 800\n",
        "\n",
        "# os.makedirs('/content/drive/MyDrive/Data/Original_Images')\n",
        "# for i in range(1,nc+1):\n",
        "#     os.mkdir('/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/')\n",
        "\n",
        "# for i in range(1,nc+1):\n",
        "#     shutil.copy2(directory + str(i) + '/bb_info.txt', '/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/')\n",
        "\n",
        "# for i in range(1,nc+1):\n",
        "#     print(\"Working on \"+str(i))\n",
        "#     new_dir = directory + str(i) + '/'\n",
        "#     for f in listdir(new_dir):\n",
        "#         if f.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "#             image = Image.open(new_dir + f)\n",
        "#             # image = image.resize((res,res),Image.ANTIALIAS)\n",
        "#             image.save('/content/drive/MyDrive/Data/Original_Images/' + str(i) + '/' + f)\n",
        "# print(\"Completed\")"
      ],
      "metadata": {
        "id": "rZJXoxwBsPCQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for modifying the bounding boxes in yolo format\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# modify the directories accordingly\n",
        "datapath = '/content/drive/MyDrive/Data/Original_Images'\n",
        "labelpath = '/content/drive/MyDrive/Data/Original_Images/labels'\n",
        "classfilename = '/content/drive/MyDrive/Data/For_Colab/foods.names'\n",
        "\n",
        "def convert_yolo_bbox(img_size, box):\n",
        "    # img_bbox file format is [0:img] [1:left X] [2:bottom Y] [3:right X] [4:top Y]\n",
        "    dw = 1./img_size[0]\n",
        "    dh = 1./img_size[1]\n",
        "    x = (int(box[1]) + int(box[3]))/2.0\n",
        "    y = (int(box[2]) + int(box[4]))/2.0\n",
        "    w = abs(int(box[3]) - int(box[1]))\n",
        "    h = abs(int(box[4]) - int(box[2]))\n",
        "    x *= dw\n",
        "    w *= dw\n",
        "    y *= dh\n",
        "    h *= dh\n",
        "    # yolo_bbox file format is center x, y and width, height\n",
        "    return (x,y,w,h)\n",
        "\n",
        "def generate_bbox_file(classid):\n",
        "    dataDir = os.path.join(datapath, str(classid))\n",
        "    labelDir = os.path.join(labelpath, str(classid))\n",
        "    bb_filename = os.path.join(dataDir, 'bb_info.txt')\n",
        "    if not os.path.exists(labelDir):\n",
        "        os.makedirs(labelDir)\n",
        "    with open(bb_filename) as fp:\n",
        "        for line in fp.readlines():\n",
        "            # img_bbox file is [0:img] [1:left X] [2:bottom Y] [3:right X] [4:top Y]\n",
        "            img_bbox = line.strip('\\n').split(' ')\n",
        "            if img_bbox[0] != 'img':\n",
        "                image_filename = os.path.join(dataDir, img_bbox[0]+'.jpg')\n",
        "                yolo_label_filename = os.path.join(labelDir, img_bbox[0]+'.txt')\n",
        "                with open(yolo_label_filename, 'w') as f:\n",
        "                    img = Image.open(image_filename)\n",
        "                    yolo_bbox = convert_yolo_bbox(img.size, img_bbox)\n",
        "                    # if (yolo_bbox[2] > 1) or (yolo_bbox[3] > 1):\n",
        "                    #     print(\"image %s bbox is \" %(image_filename) + ' '.join(map(str, yolo_bbox)))\n",
        "                    f.write(str(classid-1) + ' ' + ' '.join(map(str, yolo_bbox)) + '\\n')\n",
        "                    img.close()\n",
        "                    f.close()\n",
        "        fp.close()\n",
        "\n",
        "classid = 0\n",
        "classid2name = {}\n",
        "if os.path.exists(classfilename):\n",
        "    with open(classfilename) as cf:\n",
        "        for line in cf.readlines():\n",
        "            classname = line.strip('\\n')\n",
        "            classid = classid + 1\n",
        "            classid2name[classid] = classname\n",
        "\n",
        "for id in classid2name.keys():\n",
        "    print(\"Generating %d %s\" %(id, classid2name[id]))\n",
        "    generate_bbox_file(id)\n",
        "print('Completed')"
      ],
      "metadata": {
        "id": "I6AhF2sshOQv",
        "outputId": "e12a6758-1ddc-494d-a9b3-a340a57f5fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 1 rice\n",
            "Generating 2 toast\n",
            "Generating 3 omelet\n",
            "Generating 4 fish\n",
            "Generating 5 salad\n",
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the \"Training_Images\" folder first (if present)\n",
        "# %rm -rf /content/UECFOOD100\n",
        "# code for spliting both images and labels for training and validation\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from os.path import isfile, join\n",
        "from random import randint\n",
        "from os import listdir\n",
        "\n",
        "directory = '/content/drive/MyDrive/Data/Original_Images/'\n",
        "nc = 5\t# number of catagories\n",
        "\n",
        "def make_directories():\n",
        "\tos.makedirs('/content/drive/MyDrive/Data/Training_Images/images/train')\n",
        "\tos.mkdir('/content/drive/MyDrive/Data/Training_Images/images/val/')\n",
        "\tos.makedirs('/content/drive/MyDrive/Data/Training_Images/labels/train')\n",
        "\tos.mkdir('/content/drive/MyDrive/Data/Training_Images/labels/val/')\n",
        "\n",
        "def split_files(probability):\n",
        "\tt=0\n",
        "\tv=0\n",
        "\tfor i in range(1,nc+1):\n",
        "\t\tprint(\"Working on \"+str(i))\n",
        "\t\tnew_dir = directory + str(i) + '/'\n",
        "\t\tfor f in listdir(new_dir):\n",
        "\t\t\tif isfile(join(new_dir, f)) and f.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "\t\t\t\tfile_name = os.path.splitext(f)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tif(randint(1, 100) <= probability):\t\n",
        "\t\t\t\t\tsplit = 'train/'\n",
        "\t\t\t\t\tt +=1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsplit = 'val/'\n",
        "\t\t\t\t\tv += 1\n",
        "\n",
        "\t\t\t\timgage_src = new_dir + f\n",
        "\t\t\t\timgage_dst = \"/content/drive/MyDrive/Data/Training_Images/images/\" + split\n",
        "\n",
        "\t\t\t\tlabel_src = directory + \"labels/\" + str(i) + \"/\" + file_name + \".txt\"\n",
        "\t\t\t\tlabel_dst = \"/content/drive/MyDrive/Data/Training_Images/labels/\" + split\n",
        "\n",
        "\t\t\t\tshutil.copy2(imgage_src, imgage_dst)\n",
        "\t\t\t\tshutil.copy2(label_src, label_dst)\n",
        "\tprint(\"\\n\" + str(t) + \" (\" + str(100.0*t/(t+v)) + \" %) Images for training\")\n",
        "\tprint(str(v) + \" (\" + str(100.0*v/(t+v)) + \" %) Images for validation\")\n",
        "\n",
        "make_directories()\n",
        "split_files(70)\t# 70% for training and 30% for validation\n",
        "print(\"\\nTraining images stored in Google Drive under /Data/Training_Images/\")"
      ],
      "metadata": {
        "id": "8Boiut0khZuV",
        "outputId": "81dd2f0c-d446-46ee-d021-df9c6fa69c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on 1\n",
            "Working on 2\n",
            "Working on 3\n",
            "Working on 4\n",
            "Working on 5\n",
            "\n",
            "358 (71.6 %) Images for training\n",
            "142 (28.4 %) Images for validation\n",
            "\n",
            "Training images stored in Google Drive under /Data/Training_Images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do with 60 epochs for best results\n",
        "\n",
        "# !python train.py --img 800 --batch 4 --epochs 3 --data /content/yolov5/data/custom_coco.yaml --weights yolov5s.pt --cache\n",
        "!python train.py --batch 4 --epochs 9 --data /content/yolov5/data/custom_coco.yaml --weights runs/train/exp6/weights/best.pt --cache\n",
        "\n",
        "# runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "id": "yAJDyLpD0yYN",
        "outputId": "46e17110-f295-4be1-b061-8100076d1401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=runs/train/exp6/weights/best.pt, cfg=, data=/content/yolov5/data/custom_coco.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=9, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.1-110-g0ca85ed torch 1.10.0+cu111 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7033114 parameters, 7033114 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from runs/train/exp6/weights/best.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/Data/Training_Images/labels/train.cache' images and labels... 355 found, 0 missing, 0 empty, 0 corrupt: 100% 355/355 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 355/355 [00:03<00:00, 90.14it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Data/Training_Images/labels/train.cache' images and labels... 355 found, 0 missing, 0 empty, 0 corrupt: 100% 355/355 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 355/355 [00:03<00:00, 107.40it/s]\n",
            "Plotting labels to runs/train/exp7/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.44 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp7\u001b[0m\n",
            "Starting training for 9 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/8        0G   0.02613   0.01819   0.01974         7       640: 100% 89/89 [08:26<00:00,  5.69s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:57<00:00,  2.62s/it]\n",
            "                 all        355        355      0.553      0.818      0.719       0.42\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/8        0G   0.02758   0.01714   0.01973         7       640: 100% 89/89 [08:13<00:00,  5.55s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:59<00:00,  2.66s/it]\n",
            "                 all        355        355      0.593      0.714      0.703      0.414\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/8        0G   0.03283   0.01731   0.02035        10       640: 100% 89/89 [08:14<00:00,  5.56s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:59<00:00,  2.65s/it]\n",
            "                 all        355        355       0.41      0.759      0.544      0.217\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       3/8        0G   0.03303   0.01715    0.0183         6       640: 100% 89/89 [08:13<00:00,  5.55s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:58<00:00,  2.63s/it]\n",
            "                 all        355        355      0.448      0.554       0.48      0.226\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       4/8        0G   0.03232   0.01673   0.01663         6       640: 100% 89/89 [08:13<00:00,  5.55s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:59<00:00,  2.66s/it]\n",
            "                 all        355        355      0.651      0.772      0.778      0.424\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       5/8        0G   0.03308   0.01657   0.01571         9       640: 100% 89/89 [08:19<00:00,  5.62s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:59<00:00,  2.65s/it]\n",
            "                 all        355        355      0.699      0.855      0.825      0.427\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       6/8        0G   0.02685   0.01614   0.01523        10       640: 100% 89/89 [08:14<00:00,  5.56s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:58<00:00,  2.64s/it]\n",
            "                 all        355        355      0.708      0.813      0.808      0.488\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       7/8        0G   0.02794   0.01568   0.01546         8       640: 100% 89/89 [08:19<00:00,  5.62s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:58<00:00,  2.64s/it]\n",
            "                 all        355        355      0.798      0.903      0.904      0.569\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       8/8        0G   0.02386   0.01506   0.01507         7       640: 100% 89/89 [08:18<00:00,  5.60s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:59<00:00,  2.65s/it]\n",
            "                 all        355        355       0.85      0.878      0.909      0.579\n",
            "\n",
            "9 epochs completed in 1.542 hours.\n",
            "Optimizer stripped from runs/train/exp7/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp7/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp7/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 45/45 [01:56<00:00,  2.58s/it]\n",
            "                 all        355        355       0.85      0.878      0.908      0.579\n",
            "                rice        355         71      0.729          1      0.881       0.59\n",
            "               toast        355         69       0.91      0.739      0.897      0.597\n",
            "              omelet        355         74      0.921      0.919      0.955      0.589\n",
            "                fish        355         71      0.854      0.859      0.905      0.533\n",
            "               salad        355         70      0.835       0.87      0.903      0.588\n",
            "Results saved to \u001b[1mruns/train/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# detect a custom image\n",
        "!python custom_detect.py --weights runs/train/exp7/weights/best.pt --conf 0.5 --source /content/test.jpg"
      ],
      "metadata": {
        "id": "FnsQjuPW03oO",
        "outputId": "ce43877e-dc38-4edb-def4-89cc1167d67e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv5 ðŸš€ v6.1-110-g0ca85ed torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/test.jpg: 480x640 1 rice, 1 omelet, Done. (0.325s)\n",
            "Speed: 3.1ms pre-process, 325.1ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Images saved in \u001b[1mruns/detect/exp5\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "YOLOv5",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}